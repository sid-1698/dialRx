{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1516e8d6-5b60-4984-ad05-21278407e2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163740</td>\n",
       "      <td>Mirtazapine</td>\n",
       "      <td>Depression</td>\n",
       "      <td>\"I&amp;#039;ve tried a few antidepressants over th...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>February 28, 2012</td>\n",
       "      <td>22</td>\n",
       "      <td>neutral</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206473</td>\n",
       "      <td>Mesalamine</td>\n",
       "      <td>Crohn's Disease, Maintenance</td>\n",
       "      <td>\"My son has Crohn&amp;#039;s disease and has done ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>May 17, 2009</td>\n",
       "      <td>17</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159672</td>\n",
       "      <td>Bactrim</td>\n",
       "      <td>Urinary Tract Infection</td>\n",
       "      <td>\"Quick reduction of symptoms\"</td>\n",
       "      <td>9.0</td>\n",
       "      <td>September 29, 2017</td>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39293</td>\n",
       "      <td>Contrave</td>\n",
       "      <td>Weight Loss</td>\n",
       "      <td>\"Contrave combines drugs that were used for al...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>March 5, 2017</td>\n",
       "      <td>35</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97768</td>\n",
       "      <td>Cyclafem 1 / 35</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I have been on this birth control for one cyc...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         drugName                     condition  \\\n",
       "0      163740      Mirtazapine                    Depression   \n",
       "1      206473       Mesalamine  Crohn's Disease, Maintenance   \n",
       "2      159672          Bactrim       Urinary Tract Infection   \n",
       "3       39293         Contrave                   Weight Loss   \n",
       "4       97768  Cyclafem 1 / 35                 Birth Control   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  \"I&#039;ve tried a few antidepressants over th...    10.0   \n",
       "1  \"My son has Crohn&#039;s disease and has done ...     8.0   \n",
       "2                      \"Quick reduction of symptoms\"     9.0   \n",
       "3  \"Contrave combines drugs that were used for al...     9.0   \n",
       "4  \"I have been on this birth control for one cyc...     9.0   \n",
       "\n",
       "                 date  usefulCount sentiment  positive  negative  neutral  \\\n",
       "0   February 28, 2012           22   neutral     False     False     True   \n",
       "1        May 17, 2009           17  positive      True     False    False   \n",
       "2  September 29, 2017            3  positive      True     False    False   \n",
       "3       March 5, 2017           35  positive      True     False    False   \n",
       "4    October 22, 2015            4  positive      True     False    False   \n",
       "\n",
       "   sentiment_label  \n",
       "0                1  \n",
       "1                2  \n",
       "2                2  \n",
       "3                2  \n",
       "4                2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('drugsComTrain_raw.tsv', delimiter='\\t')\n",
    "test_df = pd.read_csv('drugsComTest_raw.tsv', delimiter='\\t')\n",
    "\n",
    "# Define a function to classify sentiment based on review text\n",
    "def classify_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "# Apply the sentiment classification\n",
    "for df in [train_df, test_df]:\n",
    "    df['sentiment'] = df['review'].apply(classify_sentiment)\n",
    "    df['positive'] = df['sentiment'] == 'positive'\n",
    "    df['negative'] = df['sentiment'] == 'negative'\n",
    "    df['neutral'] = df['sentiment'] == 'neutral'\n",
    "\n",
    "# Convert sentiment labels to a single numerical column\n",
    "def sentiment_to_label(sentiment):\n",
    "    if sentiment == 'positive':\n",
    "        return 2\n",
    "    elif sentiment == 'neutral':\n",
    "        return 1\n",
    "    else: # negative\n",
    "        return 0\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df['sentiment_label'] = df['sentiment'].apply(sentiment_to_label)\n",
    "\n",
    "# check results\n",
    "train_df.head()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cea6043-1fe1-49f5-81b9-d2b06615a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the reviews\n",
    "def tokenize_reviews(data, max_length=256):\n",
    "    return tokenizer(data['review'].tolist(), max_length=max_length, padding='max_length', truncation=True, return_tensors='pt')\n",
    "\n",
    "train_tokens = tokenize_reviews(train_df)\n",
    "test_tokens = tokenize_reviews(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af71940-a4aa-419a-9623-af9efd2a912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DrugReviewDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}  \n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long) \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_labels = train_df['sentiment_label'].tolist()\n",
    "test_labels = test_df['sentiment_label'].tolist()\n",
    "\n",
    "train_dataset = DrugReviewDataset(train_tokens, train_labels)\n",
    "test_dataset = DrugReviewDataset(test_tokens, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "990a15bd-8b4b-4434-8e43-348c8506afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    for batch in dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        labels = batch['labels']\n",
    "        total_eval_accuracy += (predictions == labels).float().mean()\n",
    "    return total_eval_accuracy / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7843468b-4a9b-489d-b79e-478f85001ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m     25\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Initialize the model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)  \n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    val_accuracy = evaluate(model, test_loader)\n",
    "    print(f'Epoch: {epoch+1}/{epochs}, Loss: {avg_train_loss}, Validation Accuracy: {val_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f9cd65-52c9-4b12-8df4-f975017b8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, dataloader):\n",
    "    model.eval()\n",
    "    review_sentiments = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            review_sentiments.extend(predictions.cpu().numpy())\n",
    "\n",
    "    return review_sentiments\n",
    "\n",
    "# Example usage (predicting sentiments for the test dataset):\n",
    "test_predictions = predict_sentiment(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2c96e18-4ab0-4026-89f5-f62ce7e7d77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       condition      drugName  \\\n",
      "0     0</span> users found this comment helpful.        Aviane   \n",
      "1     0</span> users found this comment helpful.       Chantix   \n",
      "2     0</span> users found this comment helpful.  Depo-Provera   \n",
      "3     0</span> users found this comment helpful.        Drysol   \n",
      "5     0</span> users found this comment helpful.      Implanon   \n",
      "...                                          ...           ...   \n",
      "5558                                 zen Shoulde      Naproxen   \n",
      "5559                                 zen Shoulde       Relafen   \n",
      "5556                                 zen Shoulde         Aleve   \n",
      "5557                                 zen Shoulde    Diclofenac   \n",
      "5560                                 zen Shoulde      Voltaren   \n",
      "\n",
      "      predictedSentiment  \n",
      "0                    2.0  \n",
      "1                    2.0  \n",
      "2                    2.0  \n",
      "3                    2.0  \n",
      "5                    2.0  \n",
      "...                  ...  \n",
      "5558                 2.0  \n",
      "5559                 2.0  \n",
      "5556                 1.5  \n",
      "5557                 1.5  \n",
      "5560                 1.0  \n",
      "\n",
      "[2205 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# predicted sentiment for test data\n",
    "test_df['predictedSentiment'] = test_predictions\n",
    "\n",
    "# Calculate scores for each drug per condition\n",
    "drug_scores = test_df.groupby(['condition', 'drugName'])['predictedSentiment'].mean().reset_index()\n",
    "\n",
    "# Rank drugs for each condition based on their score\n",
    "drug_rankings = drug_scores.sort_values(['condition', 'predictedSentiment'], ascending=[True, False])\n",
    "\n",
    "# Select top 5 drugs for each condition\n",
    "top_drugs_per_condition = drug_rankings.groupby('condition').head(5)\n",
    "\n",
    "print(top_drugs_per_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "547af268-3d79-4220-b603-ea53466732c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_drugs_per_condition.to_csv(\"C:/Users/chira/Downloads/top_drugs_per_condition.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf73dbcc-095a-4fb8-ba5b-b289f3c233eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
