{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import html\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import requests\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def is_meaningful_review(text):\n",
    "    \"\"\"\n",
    "    Check if the review is meaningful (not just symbols or extremely short).\n",
    "    Args:\n",
    "    text (str): The review text to evaluate.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the text is considered a meaningful review, False otherwise.\n",
    "    \"\"\"\n",
    "    return len(text) > 15 and any(char.isalpha() for char in text)\n",
    "\n",
    "def clean_dataset(file_path):\n",
    "    \"\"\"\n",
    "    Load and clean the dataset, filtering out invalid entries and decoding HTML entities in reviews.\n",
    "    Args:\n",
    "    file_path (str): The path to the dataset file.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The cleaned pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "\n",
    "    # Clean the data\n",
    "    cleaned_data = data[\n",
    "        data['drugName'].notna() & \n",
    "        data['condition'].notna() & \n",
    "        data['condition'].apply(lambda x: isinstance(x, str) and not x.isdigit() and \" users found this comment helpful.\" not in x) &\n",
    "        data['review'].apply(is_meaningful_review)\n",
    "    ]\n",
    "\n",
    "    # Decode HTML entities in the review column\n",
    "    cleaned_data['review'] = cleaned_data['review'].apply(html.unescape)\n",
    "\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reviews dataset\n",
    "raw_df_1 = clean_dataset(\"../application/data/drugsComTest_raw.tsv\")\n",
    "raw_df_2 = clean_dataset(\"../application/data/drugsComTrain_raw.tsv\")\n",
    "df = pd.concat([raw_df_1, raw_df_2], ignore_index=True)\n",
    "df[\"drug\"] = df[\"drugName\"].apply(lambda x: x.split(\" \")[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/sid98/OMSA/04_CSE_6242_DVA/ProjectFiles/FinalFDAData/drug-drugsfda-0001-of-0001.json\", \"r\") as file:\n",
    "    fda = json.load(file)\n",
    "products = []\n",
    "cnt = 0\n",
    "for item in fda[\"results\"]:\n",
    "    try:\n",
    "        for pr in item[\"products\"]:\n",
    "            pr[\"applnNo\"] = item[\"application_number\"]\n",
    "            products.append(pr)\n",
    "    except:\n",
    "        cnt += 1\n",
    "        continue\n",
    "products = pd.DataFrame(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/sid98/OMSA/04_CSE_6242_DVA/ProjectFiles/FinalFDAData/drug-ndc-0001-of-0001.json\", \"r\") as file:\n",
    "    ndc = json.load(file)\n",
    "ndc = pd.DataFrame(ndc[\"results\"])\n",
    "ndc = ndc[['product_ndc', 'generic_name', 'labeler_name', 'brand_name', 'active_ingredients', 'finished', 'dosage_form', 'product_type', 'route', 'marketing_start_date', 'product_id', 'application_number', 'brand_name_base', 'pharm_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewDrugs = list(set(df[\"drug\"].unique()))\n",
    "products[\"brandName\"] = products[\"brand_name\"].apply(lambda x: x.split(\" \")[0].lower())\n",
    "ndc[\"brandName\"] = ndc[\"brand_name\"].apply(lambda x: x.split(\" \")[0].lower() if str(x) != \"nan\" else np.nan)\n",
    "mapping = {}\n",
    "temp = products[[\"brandName\", \"applnNo\"]].drop_duplicates(subset=[\"brandName\"]).set_index(\"brandName\")\n",
    "for drug in reviewDrugs:\n",
    "    if drug in temp.index:\n",
    "        mapping[drug] = temp.loc[drug, \"applnNo\"]\n",
    "\n",
    "temp = ndc[[\"brandName\", \"application_number\"]].drop_duplicates(subset=[\"brandName\"]).set_index(\"brandName\")\n",
    "for drug in reviewDrugs:\n",
    "    if ((drug in temp.index) and (drug not in mapping)):\n",
    "        appNo = temp.loc[drug, \"application_number\"]\n",
    "        mapping[drug] = appNo\n",
    "\n",
    "appNos = list(set(mapping.values()))\n",
    "products = products[products.applnNo.isin(appNos)].reset_index(drop=True)\n",
    "ndc = ndc[ndc.application_number.isin(appNos)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(appNo):\n",
    "    rootUrl = \"https://api.fda.gov/drug/label.json?limit=1&sort=effective_time:desc\"\n",
    "    filter = f\"openfda.application_number:{appNo}\"\n",
    "    url = f\"{rootUrl}&search={filter}\"\n",
    "    response = requests.get(url)\n",
    "    response = response.json()[\"results\"][0]\n",
    "    items = [\"indications_and_usage\", \"contraindications\", \"precautions\", \"pregnancy\", \"nursing_mothers\", \"pediatric_use\", \"adverse_reactions\"]\n",
    "    cols = list(set(items).intersection(set(response.keys())))\n",
    "    result = {\"applnNo\": appNo}\n",
    "    for item in items:\n",
    "        if item in cols:\n",
    "            result[item] = \" \".join(response[item][0].split(\" \")[len(item.split(\"_\")):])\n",
    "        else:\n",
    "            result[item] = np.nan\n",
    "    return result\n",
    "\n",
    "def adverseEvents(appNo):\n",
    "    baseUrl = \"https://api.fda.gov/drug/event.json?limit=1000\"\n",
    "    filter = f\"patient.drug.openfda.application_number:{appNo}\"\n",
    "    count = {}\n",
    "    for col in [\"serious\", \"seriousnessdeath\", \"seriousnessdisabling\", \"seriousnesshospitalization\", \"seriousnesslifethreatening\"]:\n",
    "        try:\n",
    "            url = f\"{baseUrl}&count={col}&search={filter}\"\n",
    "            response = requests.get(url)\n",
    "            count[col] = response.json()[\"results\"]\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    res = []\n",
    "    for k,val in count.items():\n",
    "        for item in val:\n",
    "            term = item[\"term\"]\n",
    "            if term == 1:\n",
    "                c = item[\"count\"]\n",
    "                res.append({\n",
    "                    \"count\": c,\n",
    "                    \"event\": k\n",
    "                })\n",
    "    res = pd.DataFrame(res)\n",
    "    if len(res) != 0:\n",
    "        res.loc[:,\"applnNo\"] = appNo\n",
    "    return res\n",
    "\n",
    "def getReactions(appNo):\n",
    "    reactions = []\n",
    "\n",
    "    baseUrl = 'https://api.fda.gov/drug/event.json?count=patient.patientweight'\n",
    "    baseFilter = f'_exists_:patient.patientweight+AND+_exists_:patient.patientsex+AND+_exists_:patient.patientagegroup+AND+patient.drug.openfda.application_number:{appNo}'\n",
    "    \n",
    "    for s in [\"1\", \"2\"]:\n",
    "        for a in [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]:\n",
    "            sexFilter = f'patient.patientsex:{s}'\n",
    "            ageFilter = f'patient.patientagegroup:{a}'\n",
    "            url = f'{baseUrl}&search={baseFilter}+AND+{sexFilter}+AND+{ageFilter}&limit=1000'\n",
    "            response = requests.get(url)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                weights = [item[\"term\"] for item in response.json()[\"results\"]]\n",
    "                weightFilter1 = \"\"\n",
    "                weightFilter2 = \"\"\n",
    "                weightFilter3 = \"\"\n",
    "\n",
    "                for weight in weights:\n",
    "                    if weight < 45:\n",
    "                        weightFilter1 += f'\"{weight}\"+OR+'\n",
    "                    elif weight > 95:\n",
    "                        weightFilter3 += f'\"{weight}\"+OR+'\n",
    "                    else:\n",
    "                        weightFilter2 += f'\"{weight}\"+OR+'\n",
    "\n",
    "                weightFilter1 = f\"patient.patientweight:({weightFilter1[:-4]})\" if weightFilter1 != \"\" else \"\"\n",
    "                weightFilter2 = f\"patient.patientweight:({weightFilter2[:-4]})\" if weightFilter2 != \"\" else \"\"\n",
    "                weightFilter3 = f\"patient.patientweight:({weightFilter3[:-4]})\" if weightFilter3 != \"\" else \"\"\n",
    "                \n",
    "                baseUrl2 = 'https://api.fda.gov/drug/event.json?count=patient.reaction.reactionmeddrapt.exact'\n",
    "                for wf,name in zip([weightFilter1, weightFilter2, weightFilter3], [\"l\", \"n\", \"h\"]):\n",
    "                    if wf != \"\":\n",
    "                        url2 = f'{baseUrl2}&search={baseFilter}+AND+{sexFilter}+AND+{ageFilter}+AND+{wf}&limit=3'\n",
    "                        response2 = requests.get(url2).json()[\"results\"]\n",
    "                        for item in response2:\n",
    "                            reactions.append({\n",
    "                                \"age\": a,\n",
    "                                \"sex\": s,\n",
    "                                \"weight\": name,\n",
    "                                \"reaction\": item[\"term\"],\n",
    "                                \"count\": item[\"count\"]\n",
    "                            })\n",
    "            elif response.status_code == 429:\n",
    "                print(\"Exceeded Rate limit\")\n",
    "                return pd.DataFrame()      \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    reactions = pd.DataFrame(reactions)\n",
    "    if len(reactions) > 0:\n",
    "        reactions.loc[:,\"applnNo\"] = appNo\n",
    "    return reactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = df.drug.unique()\n",
    "appNos = list(set([mapping[drug] for drug in drugs if drug in mapping]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = []\n",
    "# missingLabels = []\n",
    "# for i,appNo in enumerate(appNos):\n",
    "#     try:\n",
    "#         labels.append(getLabels(appNo))\n",
    "#     except KeyError:\n",
    "#         missingLabels.append(appNos)\n",
    "\n",
    "#     if i%200 == 0:\n",
    "#         print(i)\n",
    "\n",
    "# events = pd.DataFrame()\n",
    "# missingEvents = []\n",
    "# for i,appNo in enumerate(appNos[:500]):\n",
    "#     try:\n",
    "#         events = pd.concat([events, adverseEvents(appNo)], ignore_index=True)\n",
    "#     except KeyError:\n",
    "#         missingEvents.append(appNo)\n",
    "#     if i%200 == 0:\n",
    "#         print(i)\n",
    "# events.to_csv(\"./Events.csv\")\n",
    "\n",
    "# reactions = pd.DataFrame()\n",
    "# errors = []\n",
    "# for i,appNo in enumerate(appNos):\n",
    "#     try:\n",
    "#         reactions = pd.concat([reactions, getReactions(appNo)], ignore_index=True)\n",
    "#     except:\n",
    "#         errors.append(appNo)\n",
    "# reactions.to_csv(f\"./LookupData/ReactionsData/Reactions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./DrugMapping.json\", \"w\") as file:\n",
    "    json.dump(mapping, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./AppNos.pickle\", \"wb\") as file:\n",
    "    pickle.dump(appNos, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions = pd.DataFrame()\n",
    "import os\n",
    "for file in os.listdir(\"./LookupData/ReactionsData/\"):\n",
    "    df = pd.read_csv(f\"./LookupData/ReactionsData/{file}\", index_col=0)\n",
    "    reactions = pd.concat([reactions, df], ignore_index=True)\n",
    "reactions.to_csv(\"/Users/sid98/OMSA/04_CSE_6242_DVA/ProjectFiles/LookupData/Reactions_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions = pd.DataFrame()\n",
    "import os\n",
    "for file in os.listdir(\"./LookupData/ReactionsData/\"):\n",
    "    df = pd.read_csv(f\"./LookupData/ReactionsData/{file}\", index_col=0)\n",
    "    reactions = pd.concat([reactions, df], ignore_index=True)\n",
    "reactions.to_csv(\"/Users/sid98/OMSA/04_CSE_6242_DVA/ProjectFiles/LookupData/Reactions_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_calls = 400\n",
    "iteration = 5\n",
    "len(appNos[(iteration*total_calls):(iteration+1)*total_calls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2266 - 2250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "reactions_last = pd.DataFrame()\n",
    "errors = []\n",
    "for i,appNo in enumerate(appNos[2250:]):\n",
    "    try:\n",
    "        reactions_last = pd.concat([reactions_last, getReactions(appNo)], ignore_index=True)\n",
    "    except:\n",
    "        errors.append(appNo)\n",
    "    if i%10 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_last.to_csv(\"./LookupData/ReactionsData/Reactions_6_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dialRx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
